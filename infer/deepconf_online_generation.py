import openai
import json
from tqdm import tqdm
import time
import os
from datetime import datetime
import numpy as np
from collections import Counter
import pickle
# from  dynasor.core.evaluator import math_equal
import re
import pandas as pd
from sentence_transformer_utils import SentenceTransformerSimilarity

# ===========================
# Configuration
# ===========================
MODEL_PATH = "p2q"
MAX_TOKENS = 12800
RID = 0
QID = 0
PORT = 8000
DATASET_FILE = "data/p2q_testset.jsonl"

# Online algorithm parameters
WARMUP_TRACES = 16
TOTAL_BUDGET = 32
CONFIDENCE_PERCENTILE = 90
WINDOW_SIZE = 2048

# Global Sentence Transformer instance
_sentence_transformer = None

def get_sentence_transformer():
    """è·å–å…¨å±€Sentence Transformerå®ä¾‹"""
    global _sentence_transformer
    if _sentence_transformer is None:
        _sentence_transformer = SentenceTransformerSimilarity()
        _sentence_transformer.download_model()
    return _sentence_transformer

# ===========================
# Edit Distance and Scoring Functions
# ===========================
def levenshtein_distance(s1, s2):
    """Calculate Levenshtein distance between two strings"""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)

    if len(s2) == 0:
        return len(s1)

    previous_row = list(range(len(s2) + 1))
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]

def extract_net_dismantle(text):
    """Extract net and dismantle parts from text"""
    if not text:
        return None, None
    
    # Pattern to match <net>content</net><dismantle>content</dismantle>
    pattern = r'<net>(.*?)</net><dismantle>(.*?)</dismantle>'
    match = re.search(pattern, text, re.DOTALL)
    
    if match:
        net_part = match.group(1).strip()
        dismantle_part = match.group(2).strip()
        return net_part, dismantle_part
    
    return None, None

def calculate_score(voted_answer, ground_truth):
    """
    Calculate score based on net and dismantle parts using Sentence Transformer
    net_score = 1 if net parts are same, else 0
    dismantle_score = best average score from all possible mappings between dismantle parts
    final_score = net_score * dismantle_score
    """
    if not voted_answer or not ground_truth:
        return 0.0, 0.0, 0.0
    
    # Extract net and dismantle parts
    voted_net, voted_dismantle = extract_net_dismantle(voted_answer)
    truth_net, truth_dismantle = extract_net_dismantle(ground_truth)
    
    # Calculate net score (binary: 1 if same, 0 if different)
    net_score = 1.0 if (voted_net and truth_net and voted_net == truth_net) else 0.0
    
    # Calculate dismantle score using optimal mapping
    dismantle_score = 0.0
    if voted_dismantle and truth_dismantle:
        dismantle_score = calculate_dismantle_mapping_score(voted_dismantle, truth_dismantle)
    elif not voted_dismantle and not truth_dismantle:
        dismantle_score = 1.0  # Both empty, perfect match
    
    # Calculate final score
    final_score = net_score * dismantle_score
    
    return net_score, dismantle_score, final_score


def calculate_dismantle_mapping_score(voted_dismantle, truth_dismantle):
    """
    Calculate dismantle score by finding the best mapping between dismantle parts
    Split by semicolon and find the optimal one-to-one mapping using batch similarity computation
    """
    # Split by semicolon and strip whitespace
    voted_parts = [part.strip() for part in voted_dismantle.split(';') if part.strip()]
    truth_parts = [part.strip() for part in truth_dismantle.split(';') if part.strip()]
    
    # If either is empty, return 0
    if not voted_parts or not truth_parts:
        return 0.0
    
    # If lengths are different, we need to handle all possible mappings
    # For simplicity, we'll use the shorter length and find best mapping
    min_len = min(len(voted_parts), len(truth_parts))
    
    if min_len == 0:
        return 0.0
    
    # Get Sentence Transformer instance
    sentence_transformer = get_sentence_transformer()
    
    # Generate all possible permutations of truth_parts
    from itertools import permutations
    
    best_avg_score = 0.0
    
    # Collect all text pairs for batch processing
    all_text_pairs = []
    permutation_indices = []
    
    for perm_idx, perm in enumerate(permutations(truth_parts, min_len)):
        perm_start_idx = len(all_text_pairs)
        
        # Collect text pairs for this permutation
        for i in range(min_len):
            voted_part = voted_parts[i]
            truth_part = perm[i]
            
            if voted_part and truth_part:
                all_text_pairs.append((voted_part, truth_part))
        
        # Record which pairs belong to this permutation
        perm_end_idx = len(all_text_pairs)
        permutation_indices.append((perm_start_idx, perm_end_idx))
    
    # Batch compute all similarities at once
    if all_text_pairs:
        all_similarities = sentence_transformer.compute_pairs_similarity(all_text_pairs)
        
        # Process results for each permutation
        for perm_idx, (start_idx, end_idx) in enumerate(permutation_indices):
            perm_similarities = all_similarities[start_idx:end_idx]
            
            if perm_similarities:
                avg_score = sum(perm_similarities) / len(perm_similarities)
                best_avg_score = max(best_avg_score, avg_score)
    
    return best_avg_score

# ===========================
# Answer Extraction Functions
# ===========================
def extract_answer(text):
    """Extract answer from text - supports both boxed format and net/dismantle format"""
    if not text:
        return None
    
    # First try to extract net/dismantle format (our target format)
    net_dismantle_pattern = r'<net>.*?</net><dismantle>.*?</dismantle>'
    match = re.search(net_dismantle_pattern, text, re.DOTALL)
    if match:
        return match.group(0).strip()
    return None

# ===========================
# Data Loading
# ===========================
def load_aime25_jsonl(file_path=DATASET_FILE):
    """Load data from aime25.jsonl file"""
    print(f"Loading data from: {file_path}")
    
    # Check if file exists
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            for line_num, line in enumerate(file, 1):
                line = line.strip()
                if not line:  # Skip empty lines
                    print(f"Skipping empty line {line_num}")
                    continue
                try:
                    parsed_line = json.loads(line)
                    data.append(parsed_line)
                except json.JSONDecodeError as e:
                    print(f"JSON decode error at line {line_num}: {e}")
                    print(f"Line content: {repr(line[:100])}")
                    print(f"Line length: {len(line)}")
                    raise
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        raise
    
    print(f"Successfully loaded {len(data)} items")
    return data

# ===========================
# Confidence Calculation
# ===========================
def compute_confidence(logprobs):
    """Compute confidence score from logprobs."""
    confs = []
    for lp in logprobs:
        confs.append(round(-sum([l.logprob for l in lp]) / len(lp), 3))
    return confs

def compute_least_grouped(confs, group_size=WINDOW_SIZE):
    """Compute sliding window mean confidence with specified group size."""
    if len(confs) < group_size:
        return [sum(confs) / len(confs)] if confs else [0]

    sliding_means = []
    for i in range(len(confs) - group_size + 1):
        window = confs[i:i + group_size]
        sliding_means.append(round(sum(window) / len(window), 3))

    return sliding_means

# ===========================
# Voting Functions
# ===========================
def weighted_majority_vote(answers, weights):
    """Perform weighted majority voting"""
    if not answers:
        return None

    answer_weights = {}
    for answer, weight in zip(answers, weights):
        if answer is not None:
            answer_str = str(answer)
            answer_weights[answer_str] = answer_weights.get(answer_str, 0.0) + float(weight)

    if not answer_weights:
        return None

    voted_answer = max(answer_weights.keys(), key=lambda x: answer_weights[x])
    return voted_answer

# ===========================
# Trace Processing and Accuracy Calculation
# ===========================
def process_trace(choice, trace_id, ground_truth):
    """Process a single trace and calculate accuracy"""
    # Extract basic info
    text = choice.message.content
    tokens = [t.token for t in choice.logprobs.content]

    # Calculate confidence
    confs = compute_confidence([t.top_logprobs for t in choice.logprobs.content])
    sliding_window = compute_least_grouped(confs, group_size=WINDOW_SIZE)

    # Extract answer
    extracted_answer = extract_answer(text)

    # Calculate correctness using our custom scoring function
    final_score = 0.0
    if extracted_answer is not None and ground_truth is not None:
        _, _, final_score = calculate_score(extracted_answer, ground_truth)

    trace_data = {
        "trace_id": trace_id,
        "stop_reason": choice.stop_reason,
        "finish_reason": choice.finish_reason,
        "text": text,
        "tokens": tokens,
        "token_count": len(tokens),
        "confs": confs,
        "group_confs": sliding_window,
        "min_conf": min(sliding_window) if sliding_window else 0,
        "extracted_answer": extracted_answer,
        "final_score": final_score,
    }

    return trace_data

def calculate_statistics(traces, phase_name=""):
    """Calculate statistics for a list of traces"""
    if not traces:
        return {}

    total_traces = len(traces)
    total_tokens = sum(t['token_count'] for t in traces)

    # Confidence statistics
    min_confs = [t['min_conf'] for t in traces]
    final_scores = [t['final_score'] for t in traces]
    stats = {
        f"{phase_name}_traces": total_traces,
        f"{phase_name}_final_score_mean": np.mean(final_scores) if final_scores else 0,
        f"{phase_name}_final_score_std": np.std(final_scores) if final_scores else 0,
        f"{phase_name}_total_tokens": total_tokens,
        f"{phase_name}_avg_tokens_per_trace": total_tokens / total_traces if total_traces > 0 else 0,
        f"{phase_name}_min_conf_mean": np.mean(min_confs) if min_confs else 0,
        f"{phase_name}_min_conf_std": np.std(min_confs) if min_confs else 0,
    }

    return stats

# ===========================
# Process Single Question Function
# ===========================
def process_single_question(data, qid, run_id=0):
    """Process a single question and return results"""
    print("="*60)
    print("ONLINE ALGORITHM WITH ACCURACY CALCULATION")
    print("="*60)
    print(f"Model: {MODEL_PATH}")
    print(f"Question ID: {qid}")
    print(f"Run ID: {run_id}")
    print(f"Warmup traces: {WARMUP_TRACES}")
    print(f"Total budget: {TOTAL_BUDGET}")
    print(f"Confidence percentile: {CONFIDENCE_PERCENTILE}")

    # Initialize client
    client = openai.OpenAI(
        api_key="None",
        base_url=f"http://localhost:{PORT}/v1",
        timeout=None
    )

    # Get question and ground truth
    prompt = data[qid]['question']
    ground_truth = str(data[qid].get('answer', '')).strip()

    system_prompt = """ä½ æ˜¯å…ƒå®ã€‚è§‚å¯ŸåŠ©æ‰‹å’Œç”¨æˆ·çš„å†å²å¯¹è¯,è¾“å‡ºå½“å‰é—®é¢˜çš„æ”¹å†™ï¼ŒåŒ…æ‹¬è”ç½‘å’Œæ‹†è§£ã€‚

## ç”¨æˆ·é—®é¢˜ç±»åˆ«ï¼š
ç”¨æˆ·çš„é—®é¢˜å¯èƒ½å±äºä»¥ä¸‹ä¸¤ä¸ªç»´åº¦çš„ç±»åˆ«ä¹‹ä¸€ã€‚åœ¨æ‹†è§£æ—¶ï¼Œä½ éœ€è¦å…ˆåˆ¤æ–­ç”¨æˆ·é—®é¢˜çš„ç±»åˆ«ï¼Œå¹¶å‚è€ƒå¯¹åº”ç±»åˆ«çš„æ‹†è§£æ–¹å‘è¿›è¡Œæ‹†è§£ã€‚

### 1. æ ¸å¿ƒæ„å›¾ç±»å‹ï¼š
- äº‹å®æŸ¥è¯¢ï¼ˆWhat/Whoï¼‰â†’ å®šä¹‰ä¸æ¦‚å¿µæ‹†è§£
- åŸå› æŸ¥è¯¢ï¼ˆWhyï¼‰â†’ åŸå› ä¸è§£å†³æ–¹æ¡ˆæ‹†è§£
- æ–¹æ³•æŸ¥è¯¢ï¼ˆHowï¼‰â†’ æ–¹æ³•ä¸è§£å†³æ–¹æ¡ˆæ‹†è§£
- æ¯”è¾ƒæŸ¥è¯¢ï¼ˆvs/differenceï¼‰â†’ æ¯”è¾ƒä¸å·®å¼‚æ‹†è§£
- å»ºè®®æŸ¥è¯¢ï¼ˆshould/recommendationï¼‰â†’ ç­–ç•¥ä¸æ–¹æ¡ˆæ‹†è§£
- å…¶ä»–ç±»åˆ«

### 2. æ‰€å±é¢†åŸŸç±»å‹åŠå…¶æ‹†è§£æ–¹å‘ï¼š
- åŒ»ç–—å¥åº·é¢†åŸŸ â†’ ç—‡çŠ¶+åŸå› +å¤„ç†æ–¹æ³•
- æŠ€æœ¯äº§å“é¢†åŸŸ â†’ ç®€ä»‹+åŠŸèƒ½+ä½¿ç”¨æ–¹æ³•
- é‡‘èæŠ•èµ„é¢†åŸŸ â†’ ç­–ç•¥+é£é™©+æ“ä½œå»ºè®®
- æ³•å¾‹é¢†åŸŸ â†’ è§„å®š+åæœ+æ¡ˆä¾‹
- æ™¯ç‚¹æ—…æ¸¸ç±» â†’ ç¥¨åŠ¡æ—¶é—´ + æ”»ç•¥
- ç¾é£Ÿï¼ˆåº—é“ºï¼‰ç±» â†’ ç‰¹è‰²
- æ•™è‚²æ•™å­¦  â†’ çŸ¥è¯†ç‚¹ï¼ˆå®šä¹‰ / å…¬å¼ / è€ƒç‚¹ï¼‰+æ–¹æ³•ï¼ˆæŠ€å·§ / è®¡åˆ’ï¼‰+è€ƒè¯•ä¿¡æ¯ï¼ˆæ—¶é—´ / é¢˜å‹ / åˆ†æ•°çº¿ï¼‰+æ•™æ / èµ„æ–™æ¨è+å‡å­¦æ”¿ç­–+åŸ¹è®­æœºæ„é€‰æ‹©ç­‰
- èŒåœºæ±‚èŒ â†’ å²—ä½èŒè´£ã€æ‹›è˜è¦æ±‚ï¼ˆå­¦å† / æŠ€èƒ½ï¼‰+é¢è¯•æŠ€å·§ï¼ˆå¸¸è§é—®é¢˜ / åº”ç­”ç­–ç•¥ï¼‰+ç®€å†ä¼˜åŒ–æ–¹æ³•+è–ªèµ„èŒƒå›´+è¡Œä¸šå‰æ™¯+ç¦»èŒ / è·³æ§½æ³¨æ„äº‹é¡¹
- æƒ…æ„Ÿå¿ƒç† â†’ æƒ…ç»ªè¡¨ç°ï¼ˆç„¦è™‘ / æŠ‘éƒï¼‰+æˆå› åˆ†æï¼ˆå®¶åº­ / å·¥ä½œï¼‰+è°ƒèŠ‚æ–¹æ³•ï¼ˆæ²Ÿé€š / è¿åŠ¨ï¼‰+å…³ç³»å¤„ç†ï¼ˆæƒ…ä¾£ / äº²å­ï¼‰+ä¸“ä¸šå’¨è¯¢å»ºè®®
- å…¶ä»–é¢†åŸŸ(å¯é€‚å½“æ‰©å±•)

## æ³¨æ„ï¼š
1. ä½ éœ€è¦å…ˆè¯†åˆ«å‡ºç”¨æˆ·å½“å‰é—®é¢˜çš„æ ¸å¿ƒæ„å›¾ç±»åˆ«å’Œæ‰€å±é¢†åŸŸç±»åˆ«ï¼Œä»¥ä¾¿ç”¨æˆ·åç»­çš„æ‹†è§£ã€‚
2. è¯·åŠ¡å¿…ä¿è¯å½“å‰è½®æ¬¡çš„ç”¨æˆ·é—®é¢˜è¶³å¤Ÿå®Œæ•´ï¼Œæ‹†è§£çš„æŒ‡ä»£è¯éƒ½å®Œæ•´æ›¿æ¢äº†ï¼Œä¸”æ‹†è§£å¿…é¡»æ˜ç¡®ï¼Œä¸å…è®¸å‡ºç°æ¨¡ç³Šè¯ã€‚å½“ç”¨æˆ·åŸºäºå¯¹è¯æ—¥å¿—è¿›è¡Œæé—®æ—¶ï¼Œéœ€è¦å°†å¯¹è¯æ—¥å¿—ä¸­çš„ç­”æ¡ˆè¡¥å……åˆ°æ‹†è§£ã€‚
3ã€æ‹†è§£å¿…é¡»ä¸ºé’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢æ‹†è§£çš„æŸ¥è¯¢è¯­å¥ï¼Œé€‚åˆç”¨äºå¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä»¥è¡¥å……LLMç”Ÿæˆç­”æ¡ˆæ‰€éœ€ä¿¡æ¯ã€‚
4. ä¸å…è®¸ä¸¢æ‰ä»»ä½•å…³é”®è¯å’Œé™å®šè¯ï¼Œä¸å…è®¸æ·»åŠ æ— æ„ä¹‰çš„è¯å’ŒæŒ‡ä»£è¯ï¼Œå¦‚â€œæ˜¯ä»€ä¹ˆâ€ã€â€œæ˜¯è°â€ã€â€œè¿™â€ç­‰ã€‚
5. åœ¨æ‹†è§£ä¸­ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·å½“å‰é—®é¢˜çš„æ ¸å¿ƒæ„å›¾ç±»åˆ«å’Œæ‰€å±é¢†åŸŸç±»åˆ«ï¼Œå‚è€ƒä¸Šæ–‡çš„æ‹†è§£æ–¹å‘è¿›è¡Œæ‹†è§£ã€‚
6. åœ¨æ‹†è§£ä¸­ï¼Œé¦–é¡¹å¿…é¡»ä¸ºåŸå§‹queryçš„å®Œæ•´è§„èŒƒåŒ–æ€»ç»“ï¼Œè‹¥é¦–é¡¹ä¸ç”¨æˆ·é—®é¢˜å®Œå…¨ç›¸åŒåˆ™æ”¹ä¸ºâ€œ<same>â€ã€‚ä¾‹å¦‚ï¼šâ€œè´µå·2023-2025GDPâ€åº”æ‹†è§£ä¸ºâ€œ<same>;è´µå·2023å¹´GDPæ•°æ®;è´µå·2024å¹´GDPæ•°æ®;è´µå·2025å¹´GDPæ•°æ®â€ï¼Œâ€œç»“åˆè´¢æŠ¥åˆ†æä¼—å®‰åœ¨çº¿çš„ä¸šåŠ¡äº®ç‚¹ï¼Œä»¥åŠè§£é‡Šè¿‘æœŸè‚¡ä»·çš„æš´æ¶¨åŸå› â€åº”æ‹†è§£ä¸ºâ€œç»“åˆè´¢æŠ¥åˆ†æä¼—å®‰åœ¨çº¿çš„ä¸šåŠ¡äº®ç‚¹å¹¶è§£é‡Šè¿‘æœŸè‚¡ä»·çš„æš´æ¶¨åŸå› ;ç»“åˆè´¢æŠ¥åˆ†æä¼—å®‰åœ¨çº¿çš„ä¸šåŠ¡äº®ç‚¹;ä¼—å®‰åœ¨çº¿è´¢æŠ¥ä¸­çš„ä¸šåŠ¡äº®ç‚¹åˆ†æ;è§£é‡Šä¼—å®‰åœ¨çº¿è¿‘æœŸè‚¡ä»·æš´æ¶¨çš„åŸå› ;ä¼—å®‰åœ¨çº¿è¿‘æœŸè‚¡ä»·æš´æ¶¨çš„å…·ä½“é©±åŠ¨å› ç´ â€
7. å½“ç”¨æˆ·é—®é¢˜ä¸­å‡ºç°æ¨¡ç³Šæ—¶é—´æ—¶ï¼Œéœ€è¦å‚è€ƒé»˜è®¤æ—¶é—´ä¿®æ”¹ä¸ºå‡†ç¡®æ—¶é—´ï¼Œå¦‚ä»Šå¤©ã€æ˜å¤©ç­‰ã€‚
8. æ‹†è§£ä¸å…è®¸ä¿®æ”¹è‹±æ–‡ä¸“æœ‰åè¯ã€‚
9. å½“ç”¨æˆ·é—®é¢˜ä¸­å‡ºç°å¤šä¸ªå¯¹æ¯”æ—¶ï¼Œç¬¬ä¸€ä¸ªæ‹†è§£éœ€è¦ä¿æŒå®Œæ•´è¯­æ„ï¼Œå…¶ä»–åç»­æ‹†è§£éœ€è¦ä¸ºå„ä¸ªçš„ä¿¡æ¯æŸ¥è¯¢ã€‚ä¾‹å¦‚ï¼šâ€œvivoiqooneo10Pro+å’Œvivoiqooneo9sProè¶…è¯¦ç»†æ¯”å¯¹â€åº”æ‹†è§£ä¸ºâ€œvivoiqooneo10Pro+å’Œvivoiqooneo9sProå¯¹æ¯”;vivoiqooneo10Pro+å‚æ•°;vivoiqooneo9sProå‚æ•°;vivoiqooneo10Pro+æ€§èƒ½;vivoiqooneo9sProæ€§èƒ½â€
10. æ‹†è§£å¿…é¡»éµå¾ªç”¨æˆ·å½“å‰é—®é¢˜å‡ºç°çš„å†…å®¹ï¼Œä¸è¦è¿›è¡Œè¿‡å¤šæ‰©å±•ã€‚
11. æ¯ä¸ªæ‹†è§£éƒ½æ˜¯ç‹¬ç«‹çš„æ‹†è§£è¯­å¥ï¼Œå½“ç”¨æˆ·æœ‰å¤šé‡æ¡ä»¶æ—¶ï¼Œæ¯ä¸ªæ‹†è§£å‡éœ€è¦ä¿ç•™æ‰€æœ‰å‰ç½®æ¡ä»¶ï¼Œå°¤å…¶æ˜¯ç”¨æˆ·å½“å‰é—®é¢˜è¶…é•¿æ—¶ï¼Œä¸è¦å‡ºç°ä¾èµ–ä¸å…¶ä»–æ‹†è§£queryçš„æ‹†è§£ã€‚
12. æ‹†è§£æ•°é‡ä¸è¦è¿‡å¤šï¼Œå°½é‡ä¸è¶…è¿‡8ä¸ªã€‚
13. ä¸è¦å‡ºç°è¯­æ„ç›¸ä¼¼çš„æ‹†è§£ã€‚
14. åªæœ‰ä¸ªäººèƒ½åŠ›ã€ç¿»è¯‘ã€å…¬å¼è®¡ç®—ã€æ‰“æ‹›å‘¼ã€é—²èŠã€ä»£ç è§£æã€ç®€å•æ¨ç†é¢˜ã€ç®—å‘½ã€èµ·åã€å¿ƒç†å’¨è¯¢æƒ…æ„Ÿæ²Ÿé€šç±»ç­‰æ— éœ€è”ç½‘ï¼Œå…¶ä»–é—®é¢˜å¦‚ä¸“æœ‰åè¯è§£é‡Šç­‰å‡éœ€è¦è”ç½‘ã€‚
15. é»˜è®¤ä½ç½®ä¸ºåŒ—äº¬

## æ—¶é—´è½¬æ¢è§„åˆ™
éœ€è¦å°†ç”¨æˆ·è¾“å…¥ä¸­çš„æ—¶é—´ç›¸å…³è¡¨è¾¾ï¼ˆå¦‚â€œæœ¬å‘¨â€ã€â€œä»Šå¹´â€ã€â€œè¿‘å‡ å¹´â€ç­‰ï¼‰å‡†ç¡®æ˜ å°„ä¸ºå…·ä½“çš„æ—¶é—´èŒƒå›´æˆ–æ—¶é—´ç‚¹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œè§£æå’Œæ˜ å°„ï¼š

### 1. æ—¶æ•ˆpatternè§£æè§„åˆ™

| æ—¶é—´è¡¨è¾¾         | æ˜ å°„è§„åˆ™ï¼ˆèŒƒå›´/ç‚¹ï¼‰                 | ç¤ºä¾‹ï¼ˆä»¥2025å¹´6æœˆ1æ—¥ä¸ºä¾‹ï¼‰                   |
|------------------|-------------------------------------|-----------------------------------------------|
| æœ¬å‘¨/è¿™å‘¨/æœ€è¿‘ä¸€å‘¨ | æœ¬å‘¨å‘¨ä¸€è‡³å‘¨æ—¥ä»¥åŠæœ¬å‘¨æ¯ä¸€å¤©        | 2025å¹´6æœˆ1æ—¥-2025å¹´6æœˆ7æ—¥ï¼Œ2025å¹´6æœˆ1æ—¥ï¼Œ2025å¹´6æœˆ2æ—¥ï¼Œ2025å¹´6æœˆ3æ—¥ï¼Œ2025å¹´6æœˆ4æ—¥ï¼Œ2025å¹´6æœˆ5æ—¥ï¼Œ2025å¹´6æœˆ6æ—¥ï¼Œ2025å¹´6æœˆ7æ—¥|
| æœ¬æœˆ             | å½“å‰è‡ªç„¶æœˆ                          | 2025å¹´6æœˆ                                     |
| ä»Šæ—¥             | å½“å‰æ—¥æœŸ                            | 2025å¹´6æœˆ1æ—¥                                  |
| ä»Šå¹´             | å½“å‰å¹´ä»½                            | 2025å¹´                                        |
| å»å¹´             | ä¸Šä¸€ä¸ªå¹´ä»½                           | 2024å¹´                                        |
| è¿‘å‡ å¤©/æœ€è¿‘å‡ å¤©    | å½“å‰æ—¥æœŸå¾€å‰æ¨7å¤©ä»¥åŠè¯¥èŒƒå›´çš„æ¯ä¸€å¤©   | 2025å¹´5æœˆ26æ—¥-2025å¹´6æœˆ1æ—¥ï¼Œ2025å¹´5æœˆ26æ—¥ï¼Œ2025å¹´5æœˆ27æ—¥ï¼Œ2025å¹´5æœˆ28æ—¥ï¼Œ2025å¹´5æœˆ29æ—¥ï¼Œ2025å¹´5æœˆ30æ—¥ï¼Œ2025å¹´5æœˆ31æ—¥ï¼Œ2025å¹´6æœˆ1æ—¥|
| è¿‘å‡ æœˆ           | å½“å‰æœˆåŠå¾€å‰æ¨è‹¥å¹²æœˆ                | 2025å¹´6æœˆï¼Œ2025å¹´5æœˆï¼Œ2024å¹´4æœˆ               |
| è¿‘å‡ å¹´           | å½“å‰å¹´åŠå¾€å‰æ¨è‹¥å¹²å¹´                | 2025å¹´ï¼Œ2024å¹´ï¼Œ2023å¹´                        |
| è¿‘ä¸¤å¹´           | å½“å‰å¹´åŠä¸Šä¸€ä¸ªå¹´ä»½                  | 2025å¹´ï¼Œ2024å¹´                                |
| å†å¹´             | å½“å‰å¹´åŠæ‰€æœ‰å¾€å¹´                    | 2025å¹´ï¼Œ2024å¹´ï¼Œ2023å¹´                        |
| å†å¹´ä»Šæ—¥         | å½“å‰æ—¥æœŸåŠæ‰€æœ‰å¾€å¹´åŒæ—¥              | 2025å¹´6æœˆ1æ—¥ï¼Œ2024å¹´6æœˆ1æ—¥ï¼Œ2023å¹´6æœˆ1æ—¥       |
| æœ¬å­£åº¦/æœ¬Qå­£åº¦   | å½“å‰å­£åº¦æ‰€æœ‰æœˆä»½                    | 2025å¹´4æœˆï¼Œ2025å¹´5æœˆï¼Œ2025å¹´6æœˆï¼Œ2025å¹´Q2ï¼Œç¬¬äºŒå­£åº¦  |
| ä¸Šå­£åº¦/ä¸Šä¸€å­£åº¦  | ä¸Šä¸€å­£åº¦æ‰€æœ‰æœˆä»½                    | 2025å¹´1æœˆï¼Œ2025å¹´2æœˆï¼Œ2025å¹´3æœˆï¼Œ2025å¹´Q1ï¼Œç¬¬ä¸€å­£åº¦   |
| ä¸Šä¸ªæœˆ/ä¸Šæœˆ       | ä¸Šä¸€ä¸ªæœˆä»½                           | 2025å¹´5æœˆ                                     |
| ä¸Šå‘¨             | ä¸Šå‘¨å‘¨ä¸€è‡³å‘¨æ—¥ä»¥åŠä¸Šå‘¨æ¯å¤©          | 2025å¹´5æœˆ25æ—¥-2025å¹´5æœˆ31æ—¥ï¼Œ2025å¹´5æœˆ25æ—¥ï¼Œ2025å¹´5æœˆ26æ—¥ï¼Œ2025å¹´5æœˆ27æ—¥ï¼Œ2025å¹´5æœˆ28æ—¥ï¼Œ2025å¹´5æœˆ29æ—¥ï¼Œ2025å¹´5æœˆ30æ—¥ï¼Œ2025å¹´5æœˆ31æ—¥|
| è¿‘æœŸ             | å½“å‰æœˆ                              | 2025å¹´6æœˆ                                     |
| æœ€æ–°             | å½“å‰æœˆ                              | 2025å¹´6æœˆ                                     |
| æœ€è¿‘             | å½“å‰æœˆ                              | 2025å¹´6æœˆ                                     |
| ç°åœ¨             | å½“å‰æ—¥æœŸ                            | 2025å¹´6æœˆ1æ—¥                                  |
| æ˜å¤©/æ˜æ—¥        | å½“å‰æ—¥æœŸ+1å¤©                        | 2025å¹´6æœˆ2æ—¥                                  |
| æœªæ¥ä¸€å‘¨         | å½“å‰æ—¥æœŸè‡³+7å¤©                  | 2025å¹´6æœˆ1æ—¥-2025å¹´6æœˆ7æ—¥ï¼Œ2025å¹´6æœˆ1æ—¥ï¼Œ2025å¹´6æœˆ2æ—¥ï¼Œ2025å¹´6æœˆ3æ—¥ï¼Œ2025å¹´6æœˆ4æ—¥ï¼Œ2025å¹´6æœˆ5æ—¥ï¼Œ2025å¹´6æœˆ6æ—¥ï¼Œ2025å¹´6æœˆ7æ—¥|
| æœªæ¥ä¸€ä¸ªæœˆ       | å½“å‰æ—¥æœŸ+1å¤©è‡³+1æœˆä»¥åŠä¸‹ä¸€ä¸ªæœˆä»½        | 2025å¹´6æœˆ2æ—¥-2025å¹´7æœˆ2æ—¥ï¼Œ2025å¹´6æœˆ            |
| ä¸‹å‘¨             | ä¸‹ä¸€ä¸ªè‡ªç„¶å‘¨ä»¥åŠä¸‹å‘¨çš„æ¯ä¸€å¤©          | 2025å¹´6æœˆ8æ—¥-2025å¹´6æœˆ14æ—¥ï¼Œ2025å¹´6æœˆ8æ—¥ï¼Œ2025å¹´6æœˆ9æ—¥ï¼Œ2025å¹´6æœˆ10æ—¥ï¼Œ2025å¹´6æœˆ11æ—¥ï¼Œ2025å¹´6æœˆ12æ—¥ï¼Œ2025å¹´6æœˆ13æ—¥ï¼Œ2025å¹´6æœˆ14æ—¥ |
| æœ€è¿‘**ä¸ªäº¤æ˜“æ—¥   | å½“å‰æ—¥æœŸå¾€å‰æ¨æŒ‡å®šäº¤æ˜“æ—¥æ•°åŠè¯¥èŒƒå›´çš„æ¯ä¸€å¤©   | 2025å¹´5æœˆ30æ—¥-2025å¹´6æœˆ1æ—¥ï¼ˆè¿‘3ä¸ªäº¤æ˜“æ—¥ï¼‰ï¼Œ2025å¹´5æœˆ30æ—¥ï¼Œ2025å¹´5æœˆ31æ—¥ï¼Œ2025å¹´6æœˆ1æ—¥|
| **è‚¡ç¥¨**/èµ°åŠ¿/ä»·æ ¼ | å½“å¤©æˆ–å½“æœˆ                         | 2025å¹´6æœˆ1æ—¥ï¼ˆå½“å¤©ï¼‰ã€2025å¹´6æœˆï¼ˆå½“æœˆï¼‰        |
| **åº”å­£**         | å½“å‰æœˆ                              | 2025å¹´6æœˆ                                     |
| **ç›®å‰**         | å½“å‰å¹´                              | 2025å¹´                                        |
| æ”¿ç­–/æ•°æ®/æˆ¿ä»·   | å½“å‰æœˆæˆ–å¹´ï¼Œè§†å…·ä½“é¢†åŸŸè€Œå®š           | 2025å¹´6æœˆæˆ–2025å¹´                             |
| ä¸­è€ƒ/é«˜è€ƒ        | å½“å‰å¹´                              | 2025å¹´                                        |

### 2. æ’è¡Œæ¦œæ—¶æ•ˆè¡¥å…¨è§„åˆ™

| é¢‘ç‡      | è¡¥å…¨æŒ‡ä»¤è¯ | ç¤ºä¾‹                          | ç‰¹å¾è¯´æ˜                          |
|-----------|------------|-------------------------------|-----------------------------------|
| å¹´åº¦æ›´æ–°  | 2025       | QSä¸–ç•Œå¤§å­¦æ’åã€å…¬å¸å¹´æŠ¥ç­‰    | æƒå¨æ€§å¼ºï¼Œè¦†ç›–å®è§‚è¯„ä¼°            |
| æœˆ/å‘¨æ›´æ–° | 2025å¹´6æœˆ  | App Storeä¸‹è½½æ¦œã€æœˆåº¦æ¦œå•ç­‰   | åæ˜ ä¸­çŸ­æœŸè¶‹åŠ¿                    |
| å¤©çº§/å®æ—¶ | 2025å¹´6æœˆ1æ—¥ | çƒ­æœæ¦œã€å³æ—¶æ¦œå•ç­‰           | æ•æ‰å³æ—¶åŠ¨æ€                      |
| å­£åº¦/åŠå¹´ | 2025å¹´     | å°ç±³å­£åº¦æŠ¥ã€ä¼ä¸šè´¢æŠ¥å­£æ¦œå•ç­‰  | è´¢æŠ¥ã€éƒ¨åˆ†ä¸“ä¸šé¢†åŸŸæ¦œå•            |

### 3. è¾“å‡ºè¦æ±‚

- è¯·å°†ç”¨æˆ·è¾“å…¥ä¸­çš„æ—¶é—´è¡¨è¾¾ï¼Œç»Ÿä¸€æ˜ å°„ä¸ºå…·ä½“çš„æ—¶é—´ç‚¹æˆ–æ—¶é—´æ®µï¼ˆä»¥â€œå¹´â€ã€â€œæœˆâ€ã€â€œæ—¥â€ä¸ºå•ä½ï¼‰ã€‚
- å¦‚é‡ä¸æ˜ç¡®è¡¨è¾¾ï¼Œä¼˜å…ˆç»“åˆè¯­å¢ƒåŠä¸Šè¿°è§„åˆ™åˆç†æ¨æ–­ã€‚
- è‹¥æ¶‰åŠæ’è¡Œæ¦œã€æ¦œå•ã€æ”¿ç­–ã€è´¢æŠ¥ç­‰ï¼Œç»“åˆå…¶æ›´æ–°é¢‘ç‡è¡¥å…¨æ—¶é—´ç²’åº¦ã€‚
- é™¤äº†è¦è§£æå‡ºå…·ä½“çš„æ—¶é—´èŒƒå›´ï¼Œè¿˜è¦æ‹†åˆ†åˆ°æ¯ä¸€å¤©æˆ–æ¯ä¸ªæœˆæˆ–æ¯ä¸€å¹´ã€‚
   ä¾‹å¦‚ï¼šâ€˜2025å¹´3æœˆ10å·è‡³2025å¹´3æœˆ13å·çš„è¶³çƒæ¯”èµ›â€™éœ€è¦æ‹†åˆ†ä¸ºâ€˜<same>;2025å¹´3æœˆ10å·çš„è¶³çƒæ¯”èµ›;2025å¹´3æœˆ11å·çš„è¶³çƒæ¯”èµ›;2025å¹´3æœˆ12å·çš„è¶³çƒæ¯”èµ›;2025å¹´3æœˆ13å·çš„è¶³çƒæ¯”èµ›â€˜
   ä¾‹å¦‚ï¼šâ€˜2025å¹´3æœˆè‡³5æœˆçš„é‡‘ä»·â€™éœ€è¦æ‹†åˆ†ä¸ºâ€˜<same>;2025å¹´3æœˆé‡‘ä»·;2025å¹´4æœˆé‡‘ä»·;2025å¹´5æœˆé‡‘ä»·â€™
   ä¾‹å¦‚ï¼šâ€˜2025å¹´-2026å¹´çš„æ±Ÿè‹GDPâ€™éœ€è¦æ‹†åˆ†ä¸ºâ€˜<same>;2025å¹´çš„æ±Ÿè‹GDP;2026å¹´çš„æ±Ÿè‹GDPâ€™

~~~å½“å‰æ—¶é—´ä¸ºï¼š
2025å¹´9æœˆ3æ—¥18:00:00
~~~

è¾“å‡ºç­”æ¡ˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š
<net>æ˜¯å¦è”ç½‘</net><dismantle>æ‹†è§£å†…å®¹</dismantle>
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ç”¨æˆ·:{prompt}"}
    ]

    print(f"\nQuestion: {prompt}")
    print(f"Ground Truth: {ground_truth}")

    # ===========================
    # WARMUP PHASE
    # ===========================
    print(f"\n{'-'*40}")
    print("WARMUP PHASE")
    print(f"{'-'*40}")

    t0 = time.time()
    responses = client.chat.completions.create(
        model=MODEL_PATH,
        messages=messages,
        max_tokens=MAX_TOKENS,
        temperature=0.6,
        top_p=0.95,
        logprobs=True,
        top_logprobs=20,
        n=WARMUP_TRACES,
        extra_body={"top_k": 0},
    )
    t1 = time.time()

    # Process warmup traces
    warmup_traces = []
    min_confs = []

    for j in range(WARMUP_TRACES):
        trace_data = process_trace(responses.choices[j], j, ground_truth)
        warmup_traces.append(trace_data)
        min_confs.append(trace_data["min_conf"])

    # Calculate confidence bar
    conf_bar = float(np.percentile(min_confs, CONFIDENCE_PERCENTILE))

    # Calculate warmup statistics
    warmup_stats = calculate_statistics(warmup_traces, "warmup")

    print(f"Warmup time: {t1 - t0:.2f}s")
    print(f"Confidence bar (P{CONFIDENCE_PERCENTILE}): {conf_bar:.4f}")
    print(f"Warmup final score mean: {warmup_stats['warmup_final_score_mean']:.4f}")
    print(f"Warmup final score std: {warmup_stats['warmup_final_score_std']:.4f}")
    print(f"Warmup total tokens: {warmup_stats['warmup_total_tokens']}")
    print(f"Warmup avg tokens per trace: {warmup_stats['warmup_avg_tokens_per_trace']:.1f}")

    # Show some example results
    print(f"\nFirst 3 warmup traces:")
    for i, trace in enumerate(warmup_traces[:3]):
        print(f"  Trace {i}: {trace['extracted_answer']} (score: {trace['final_score']:.4f}, conf: {trace['min_conf']:.4f}, tokens: {trace['token_count']})")

    # ===========================
    # FINAL PHASE
    # ===========================
    print(f"\n{'-'*40}")
    print("FINAL PHASE (with early stopping)")
    print(f"{'-'*40}")

    real_gen = TOTAL_BUDGET - WARMUP_TRACES

    t3 = time.time()
    responses = client.chat.completions.create(
        model=MODEL_PATH,
        messages=messages,
        max_tokens=MAX_TOKENS,
        temperature=0.6,
        top_p=0.95,
        logprobs=True,
        top_logprobs=20,
        n=real_gen,
        extra_body={
            "top_k": 0,
            "vllm_xargs": {
                'enable_conf': True,
                'window_size': WINDOW_SIZE,
                'threshold': conf_bar
            }
        }
    )
    t4 = time.time()

    # Process final traces
    final_traces = []
    for j in range(len(responses.choices)):
        trace_data = process_trace(responses.choices[j], WARMUP_TRACES + j, ground_truth)
        final_traces.append(trace_data)

    # Calculate final statistics
    final_stats = calculate_statistics(final_traces, "final")

    print(f"Final time: {t4 - t3:.2f}s")
    print(f"Final traces generated: {len(final_traces)} (requested: {real_gen})")
    print(f"Final final score mean: {final_stats['final_final_score_mean']:.4f}")
    print(f"Final final score std: {final_stats['final_final_score_std']:.4f}")
    print(f"Final total tokens: {final_stats['final_total_tokens']}")
    print(f"Final avg tokens per trace: {final_stats['final_avg_tokens_per_trace']:.1f}")

    # Show some example results
    print(f"\nFirst 3 final traces:")
    for i, trace in enumerate(final_traces[:3]):
        print(f"  Trace {i}: {trace['extracted_answer']} (score: {trace['final_score']:.4f}, conf: {trace['min_conf']:.4f}, tokens: {trace['token_count']})")

    # ===========================
    # OVERALL STATISTICS
    # ===========================
    print(f"\n{'-'*40}")
    print("OVERALL STATISTICS")
    print(f"{'-'*40}")

    all_traces = warmup_traces + final_traces
    overall_stats = calculate_statistics(all_traces, "overall")

    total_time = t4 - t0
    warmup_time = t1 - t0
    final_time = t4 - t3

    print(f"Total time: {total_time:.2f}s (warmup: {warmup_time:.2f}s, final: {final_time:.2f}s)")
    print(f"Overall traces: {len(all_traces)}")
    print(f"Overall final score mean: {overall_stats['overall_final_score_mean']:.4f}")
    print(f"Overall final score std: {overall_stats['overall_final_score_std']:.4f}")
    print(f"Overall total tokens: {overall_stats['overall_total_tokens']}")
    print(f"Overall avg tokens per trace: {overall_stats['overall_avg_tokens_per_trace']:.1f}")

    # Efficiency metrics
    tokens_per_second = overall_stats['overall_total_tokens'] / total_time
    traces_per_second = len(all_traces) / total_time

    print(f"Tokens per second: {tokens_per_second:.1f}")
    print(f"Traces per second: {traces_per_second:.2f}")

    # Early stopping analysis
    if final_traces:
        above_threshold = sum(1 for t in final_traces if t['min_conf'] >= conf_bar)
        print(f"Final traces above threshold: {above_threshold}/{len(final_traces)} ({above_threshold/len(final_traces):.2%})")

    # ===========================
    # SAVE RESULTS
    # ===========================
    results = {
        "question_id": qid,
        "run_id": run_id,
        "question": prompt,
        "ground_truth": ground_truth,
        "conf_bar": conf_bar,
        "warmup_traces": warmup_traces,
        "final_traces": final_traces,
        "statistics": {
            **warmup_stats,
            **final_stats,
            **overall_stats,
            "total_time": total_time,
            "warmup_time": warmup_time,
            "final_time": final_time,
            "tokens_per_second": tokens_per_second,
            "traces_per_second": traces_per_second,
        },
        "config": {
            "model_path": MODEL_PATH,
            "warmup_traces": WARMUP_TRACES,
            "total_budget": TOTAL_BUDGET,
            "confidence_percentile": CONFIDENCE_PERCENTILE,
            "window_size": WINDOW_SIZE,
        },
        "timestamp": datetime.now().isoformat(),
    }

    # Save results to JSON file
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("outputs", exist_ok=True)
    pickle.dump(results, open(f"outputs/q{qid}_r{run_id}_{timestamp}.pkl", 'wb'))
    print(f"Results saved to outputs/q{qid}_r{run_id}_{timestamp}.pkl")
    output_filename = f"outputs/q{qid}_r{run_id}_{timestamp}.pkl"

    print(f"\nâœ… Results saved to outputs/q{qid}_r{run_id}_{timestamp}.pkl")

    # ===========================
    # COMPARISON WITH BASELINE
    # ===========================
    print(f"\n{'-'*40}")
    print("COMPARISON ANALYSIS")
    print(f"{'-'*40}")

    # Compare warmup vs final phase
    if warmup_stats['warmup_traces'] > 0 and final_stats['final_traces'] > 0:
        score_improvement = final_stats['final_final_score_mean'] - warmup_stats['warmup_final_score_mean']
        print(f"Score change (final - warmup): {score_improvement:+.4f}")

        token_efficiency = final_stats['final_avg_tokens_per_trace'] / warmup_stats['warmup_avg_tokens_per_trace']
        print(f"Token efficiency (final/warmup): {token_efficiency:.2f}x")

    # Early stopping effectiveness
    total_requested = WARMUP_TRACES + (TOTAL_BUDGET - WARMUP_TRACES)
    total_generated = len(all_traces)
    saving_ratio = (total_requested - total_generated) / total_requested

    print(f"Traces requested: {total_requested}")
    print(f"Traces generated: {total_generated}")
    print(f"Early stopping saving: {saving_ratio:.2%}")

    # ===========================
    # VOTING FOR FINAL ANSWER
    # ===========================
    print(f"\n{'-'*40}")
    print("VOTING FOR FINAL ANSWER")
    print(f"{'-'*40}")

    # Collect answers above threshold for voting
    voting_answers = []
    voting_weights = []
    total_voting_tokens = 0

    # Add warmup traces above threshold (use confidence as weight)
    for trace in warmup_traces:
        minx = trace['min_conf']
        total_voting_tokens += trace['token_count']
        if minx >= conf_bar:
            answer = trace['extracted_answer']
            if answer is not None:
                voting_answers.append(answer)
                voting_weights.append(minx)

    # Add final traces above threshold (use weight 1)
    for trace in final_traces:
        total_voting_tokens += trace['token_count']
        # Skip traces that were stopped by gconf (early stopping)
        if trace['stop_reason'] is not None and 'gconf' in trace['stop_reason']:
            continue

        minx = trace['min_conf']
        # Note: final traces might not need threshold check since they were already filtered
        # But keeping it consistent with the reference code
        if minx >= conf_bar:
            answer = trace['extracted_answer']
            if answer is not None:
                voting_answers.append(answer)
                voting_weights.append(1)

    print(f"Traces used for voting: {len(voting_answers)}")
    print(f"Total tokens in voting traces: {total_voting_tokens}")

    # Perform weighted majority vote
    voted_answer = weighted_majority_vote(voting_answers, voting_weights)

    # Calculate score based on net and dismantle parts
    net_score, dismantle_score, final_score = calculate_score(voted_answer, ground_truth)
    
    # For backward compatibility, we can still define is_voted_correct
    # but now it's based on the final_score (you can adjust threshold as needed)
    is_voted_correct = final_score > 0.8  # Threshold for considering as "correct"
    
    print(f"Voted answer: {voted_answer}")
    print(f"Ground truth: {ground_truth}")
    print(f"Net score: {net_score:.4f}")
    print(f"Dismantle score: {dismantle_score:.4f}")
    print(f"Final score: {final_score:.4f}")
    print(f"Voted answer correct (threshold 0.8): {is_voted_correct}")

    # Show voting breakdown
    if voting_answers:
        answer_counts = Counter(voting_answers)
        print(f"\nVoting breakdown:")
        for answer, count in answer_counts.most_common():
            print(f"  {answer}: {count} votes")

    # ===========================
    # UPDATE RESULTS WITH VOTING
    # ===========================
    voting_results = {
        "voting_answers": voting_answers,
        "voting_weights": voting_weights,
        "voted_answer": voted_answer,
        "is_voted_correct": is_voted_correct,
        "net_score": net_score,
        "dismantle_score": dismantle_score,
        "final_score": final_score,
        "voting_traces_count": len(voting_answers),
        "voting_total_tokens": total_voting_tokens,
    }

    results["voting"] = voting_results
    results["statistics"]["voting_traces_count"] = len(voting_answers)
    results["statistics"]["voting_total_tokens"] = total_voting_tokens
    results["statistics"]["is_voted_correct"] = is_voted_correct
    results["statistics"]["net_score"] = net_score
    results["statistics"]["dismantle_score"] = dismantle_score
    results["statistics"]["final_score"] = final_score

    # Update the saved file with voting results
    # with open(output_filename, 'w', encoding='utf-8') as f:
    #     pickle.dump(results, f)

    # print(f"\nâœ… Results updated with voting information: {output_filename}")

    # ===========================
    # FINAL SUMMARY
    # ===========================
    print(f"\n{'='*60}")
    print("FINAL SUMMARY")
    print(f"{'='*60}")
    print(f"Question ID: {qid}")
    print(f"Confidence bar: {conf_bar:.4f}")
    print(f"Total traces generated: {len(all_traces)}")
    print(f"Traces used for voting: {len(voting_answers)}")
    print(f"Total tokens: {overall_stats['overall_total_tokens']}")
    print(f"Voting answer: {voted_answer}")
    print(f"Ground truth: {ground_truth}")
    print(f"Net score: {net_score:.4f}")
    print(f"Dismantle score: {dismantle_score:.4f}")
    print(f"Final score: {final_score:.4f}")
    print(f"Final result: {'âœ… CORRECT' if is_voted_correct else 'âŒ INCORRECT'} (threshold: 0.8)")

    # Extract net and dismantle parts from voted answer for CSV output
    voted_net, voted_dismantle = extract_net_dismantle(voted_answer) if voted_answer else (None, None)
    
    return {
        "query": prompt,
        "truth": ground_truth,
        "answer": voted_answer,
        "net": voted_net,
        "dismantle": voted_dismantle,
        "net_score": net_score,
        "dismantle_score": dismantle_score,
        "final_score": final_score,
        "is_correct": is_voted_correct,
        "question_id": qid,
        "run_id": run_id,
        "total_traces": len(all_traces),
        "voting_traces": len(voting_answers),
        "total_tokens": overall_stats['overall_total_tokens']
    }

# ===========================
# Main Function
# ===========================
def main():
    """Main function to process all questions in the dataset"""
    print("="*60)
    print("BATCH PROCESSING ALL QUESTIONS")
    print("="*60)
    print(f"Model: {MODEL_PATH}")
    print(f"Dataset: {DATASET_FILE}")
    print(f"Warmup traces: {WARMUP_TRACES}")
    print(f"Total budget: {TOTAL_BUDGET}")
    print(f"Confidence percentile: {CONFIDENCE_PERCENTILE}")

    # Load the data
    data = load_aime25_jsonl()
    print(f"Loaded {len(data)} items from {DATASET_FILE}")

    # Initialize results list
    all_results = []
    
    # Process each question
    for qid in tqdm(range(len(data)), desc="Processing questions"):
        try:
            print(f"\n{'='*80}")
            print(f"Processing Question {qid + 1}/{len(data)}")
            print(f"{'='*80}")
            
            # Process single question
            result = process_single_question(data, qid, RID)
            all_results.append(result)
            
            print(f"âœ… Completed question {qid + 1}/{len(data)}")
            
        except Exception as e:
            print(f"âŒ Error processing question {qid}: {e}")
            # Add error result
            all_results.append({
                "query": data[qid].get('question', ''),
                "truth": data[qid].get('answer', ''),
                "answer": None,
                "net": None,
                "dismantle": None,
                "net_score": 0.0,
                "dismantle_score": 0.0,
                "final_score": 0.0,
                "is_correct": False,
                "question_id": qid,
                "run_id": RID,
                "total_traces": 0,
                "voting_traces": 0,
                "total_tokens": 0,
                "error": str(e)
            })
            continue

    # ===========================
    # Save Results to CSV
    # ===========================
    print(f"\n{'='*60}")
    print("SAVING RESULTS TO CSV")
    print(f"{'='*60}")
    
    # Create DataFrame
    df = pd.DataFrame(all_results)
    
    # Select columns for CSV output
    csv_columns = ['query', 'truth', 'answer', 'net', 'dismantle']
    csv_df = df[csv_columns].copy()
    
    # Save to CSV
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"outputs/p2q_results_{timestamp}.csv"
    csv_df.to_csv(csv_filename, index=False, encoding='utf-8')
    
    print(f"âœ… CSV results saved to: {csv_filename}")
    print(f"ğŸ“Š Processed {len(all_results)} questions")
    
    # Save detailed results
    detailed_filename = f"outputs/p2q_detailed_results_{timestamp}.csv"
    df.to_csv(detailed_filename, index=False, encoding='utf-8')
    print(f"âœ… Detailed results saved to: {detailed_filename}")
    
    # ===========================
    # Summary Statistics
    # ===========================
    print(f"\n{'='*60}")
    print("SUMMARY STATISTICS")
    print(f"{'='*60}")
    
    successful_results = [r for r in all_results if 'error' not in r]
    error_count = len(all_results) - len(successful_results)
    
    if successful_results:
        avg_final_score = np.mean([r['final_score'] for r in successful_results])
        avg_net_score = np.mean([r['net_score'] for r in successful_results])
        avg_dismantle_score = np.mean([r['dismantle_score'] for r in successful_results])
        correct_count = sum([r['is_correct'] for r in successful_results])
        total_tokens = sum([r['total_tokens'] for r in successful_results])
        
        print(f"Total questions: {len(all_results)}")
        print(f"Successful: {len(successful_results)}")
        print(f"Errors: {error_count}")
        print(f"Accuracy: {correct_count}/{len(successful_results)} ({correct_count/len(successful_results):.2%})")
        print(f"Average final score: {avg_final_score:.4f}")
        print(f"Average net score: {avg_net_score:.4f}")
        print(f"Average dismantle score: {avg_dismantle_score:.4f}")
        print(f"Total tokens used: {total_tokens:,}")
        print(f"Average tokens per question: {total_tokens/len(successful_results):.0f}")
    
    return all_results

if __name__ == "__main__":
    results = main()